alertmanagerFiles:
  alertmanager.yml:
    global:
       slack_api_url: 'https://hooks.slack.com/services/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'

    receivers:
      - name: default-receiver
        slack_configs:
          - channel: '#osmose-alertmanager'
            send_resolved: true
    route:
      group_wait: 10s
      group_interval: 5m
      receiver: default-receiver
      repeat_interval: 3h

serverFiles:
  alerts:
    groups:
    - name: NodeAlerts
      rules:
      - alert: NodeCPUUsage
        expr: (100 - (avg(irate(node_cpu{mode="idle"}[5m])) BY (instance) * 100)) > 75
        for: 2m
        labels:
          severity: alert
        annotations:
          description: "{{$labels.instance}}: CPU usage is above 75% (current value is: {{ $value }})"
          summary: "{{$labels.instance}}: High CPU usage detect"

      - alert: InstanceDown
        expr: up == 0
        for: 5m
        labels:
          severity: page
        annotations:
          summary: "Instance {{ $labels.instance }} down"
          description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes."

      - alert: OutOfMemory
        expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Out of memory (instance {{ $labels.instance }})"
          description: "Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
